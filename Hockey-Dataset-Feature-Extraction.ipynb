{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T12:42:33.152714Z","iopub.status.busy":"2023-12-10T12:42:33.152331Z","iopub.status.idle":"2023-12-10T12:42:44.476658Z","shell.execute_reply":"2023-12-10T12:42:44.475799Z","shell.execute_reply.started":"2023-12-10T12:42:33.152687Z"},"trusted":true},"outputs":[],"source":["%matplotlib inline\n","import cv2\n","import os\n","import numpy as np\n","import keras\n","import matplotlib.pyplot as plt\n","from random import shuffle\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.layers import LSTM\n","from tensorflow.keras.layers import Dense, Activation\n","import sys\n","import h5py"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T12:42:44.478292Z","iopub.status.busy":"2023-12-10T12:42:44.477757Z","iopub.status.idle":"2023-12-10T12:42:44.483338Z","shell.execute_reply":"2023-12-10T12:42:44.482347Z","shell.execute_reply.started":"2023-12-10T12:42:44.478264Z"},"trusted":true},"outputs":[],"source":["def print_percentage(curr, final):\n","    # Percentage completion.\n","    p = curr / final\n","    msg = \"\\r- Percentage: {0:.1%}\".format(p)\n","\n","    # Print it.\n","    sys.stdout.write(msg)\n","    sys.stdout.flush()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T12:42:44.484919Z","iopub.status.busy":"2023-12-10T12:42:44.484583Z","iopub.status.idle":"2023-12-10T12:42:44.504239Z","shell.execute_reply":"2023-12-10T12:42:44.503496Z","shell.execute_reply.started":"2023-12-10T12:42:44.484887Z"},"trusted":true},"outputs":[],"source":["# Frame size  \n","image_size = 224\n","\n","image_size_touple = (image_size, image_size)\n","\n","# Number of channels (RGB)\n","n_channels = 3\n","\n","# Number of classes for classification (Violence-No Violence)\n","num_classes = 2\n","\n","# Number of frames per video\n","frames_per_file = 20\n","\n","# Video extension\n","video_extension = \".avi\"\n","\n","data_path = \"hockey-fight-videos/data\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T12:42:44.507858Z","iopub.status.busy":"2023-12-10T12:42:44.507455Z","iopub.status.idle":"2023-12-10T12:42:44.518028Z","shell.execute_reply":"2023-12-10T12:42:44.517150Z","shell.execute_reply.started":"2023-12-10T12:42:44.507832Z"},"trusted":true},"outputs":[],"source":["def load_rgb_frames(current_dir, file_name):\n","    \n","    in_file = os.path.join(current_dir, file_name)\n","    \n","    images = []\n","    \n","    vidcap = cv2.VideoCapture(in_file)\n","    \n","    success,image = vidcap.read()\n","        \n","    count = 0\n","\n","    while count<frames_per_file:\n","                \n","        RGB_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    \n","        res = cv2.resize(RGB_img, dsize=(image_size, image_size),\n","                                 interpolation=cv2.INTER_CUBIC)\n","    \n","        images.append(res)\n","    \n","        success,image = vidcap.read()\n","    \n","        count += 1\n","        \n","    resul = np.array(images)\n","    \n","    resul = (resul / 255.).astype(np.float16)\n","        \n","    return resul"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T12:42:44.519579Z","iopub.status.busy":"2023-12-10T12:42:44.519287Z","iopub.status.idle":"2023-12-10T12:42:44.527794Z","shell.execute_reply":"2023-12-10T12:42:44.527056Z","shell.execute_reply.started":"2023-12-10T12:42:44.519556Z"},"trusted":true},"outputs":[],"source":["def get_labels(data_path):\n","    \n","    names = []\n","\n","    labels = []\n","    \n","    \n","    for current_dir, dir_names, file_names in os.walk(data_path):\n","        \n","        for file_name in file_names:\n","            \n","            if file_name[0:2] == 'fi':\n","                labels.append([1,0])\n","                names.append(file_name)\n","            elif file_name[0:2] == 'no':\n","                labels.append([0,1])\n","                names.append(file_name)\n","                     \n","            \n","    c = list(zip(names,labels))\n","\n","    shuffle(c)\n","    \n","    names, labels = zip(*c)\n","            \n","    return names, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T12:42:44.529523Z","iopub.status.busy":"2023-12-10T12:42:44.528913Z","iopub.status.idle":"2023-12-10T12:42:44.596114Z","shell.execute_reply":"2023-12-10T12:42:44.595303Z","shell.execute_reply.started":"2023-12-10T12:42:44.529489Z"},"trusted":true},"outputs":[],"source":["\n","names, labels = get_labels(data_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T12:42:44.598136Z","iopub.status.busy":"2023-12-10T12:42:44.597426Z","iopub.status.idle":"2023-12-10T12:42:52.099802Z","shell.execute_reply":"2023-12-10T12:42:52.098952Z","shell.execute_reply.started":"2023-12-10T12:42:44.598096Z"},"trusted":true},"outputs":[],"source":["image_model = VGG16(include_top=True, weights='imagenet')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T12:42:52.101142Z","iopub.status.busy":"2023-12-10T12:42:52.100891Z","iopub.status.idle":"2023-12-10T12:42:52.112871Z","shell.execute_reply":"2023-12-10T12:42:52.112028Z","shell.execute_reply.started":"2023-12-10T12:42:52.101119Z"},"trusted":true},"outputs":[],"source":["# We will use the output of the layer prior to the final\n","# classification-layer which is named fc2. This is a fully-connected (or dense) layer.\n","transfer_layer = image_model.get_layer('block5_conv3')\n","\n","image_model_transfer = Model(inputs=image_model.input,\n","                             outputs=transfer_layer.output)\n","\n","transfer_values_size = K.int_shape(image_model_transfer.output)\n","\n","\n","print(\"The input of the VGG16 net have dimensions:\",K.int_shape(image_model.input))\n","\n","print(\"The output of the selected layer of VGG16 net have dimensions: \", transfer_values_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T12:42:52.114295Z","iopub.status.busy":"2023-12-10T12:42:52.113948Z","iopub.status.idle":"2023-12-10T12:42:52.122858Z","shell.execute_reply":"2023-12-10T12:42:52.122132Z","shell.execute_reply.started":"2023-12-10T12:42:52.114269Z"},"trusted":true},"outputs":[],"source":["import os\n","os.mkdir('/kaggle/working/train')\n","os.mkdir('/kaggle/working/valid')\n","os.mkdir('/kaggle/working/test')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T12:42:52.124301Z","iopub.status.busy":"2023-12-10T12:42:52.124011Z","iopub.status.idle":"2023-12-10T12:42:52.133265Z","shell.execute_reply":"2023-12-10T12:42:52.132391Z","shell.execute_reply.started":"2023-12-10T12:42:52.124276Z"},"trusted":true},"outputs":[],"source":["def load_data_train(vid_names, data_path, labels):\n","    \n","    count = 0\n","    \n","    tam = len(vid_names)\n","    \n","    shape = (frames_per_file,) + image_size_touple + (1,)\n","    \n","    while count<tam:\n","        \n","        video_name = vid_names[count]\n","        \n","        image_batch = np.zeros(shape=shape, dtype=np.float16)\n","    \n","        image_batch = load_rgb_frames(data_path, video_name)\n","        \n","        shape = (frames_per_file, 14, 14, 512)\n","        transfer_values = np.zeros(shape=shape, dtype=np.float16)\n","        \n","        transfer_values = \\\n","            image_model_transfer.predict(image_batch)\n","         \n","        labels1 = labels[count]\n","        \n","        aux = np.ones([20,2])\n","        \n","        labelss = labels1*aux\n","        \n","        file_path = 'train/data' + str(count+1) + '.h5'\n","        \n","        with h5py.File(file_path, 'w') as hf:\n","            hf.create_dataset('data', data = transfer_values)\n","            hf.create_dataset('labels', data = labels[count])\n","        \n","        count+=1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T12:42:52.134768Z","iopub.status.busy":"2023-12-10T12:42:52.134499Z","iopub.status.idle":"2023-12-10T12:42:52.145107Z","shell.execute_reply":"2023-12-10T12:42:52.144329Z","shell.execute_reply.started":"2023-12-10T12:42:52.134744Z"},"trusted":true},"outputs":[],"source":["def load_data_valid(vid_names, data_path, labels):\n","    \n","    count = 0\n","    \n","    tam = len(vid_names)\n","    \n","    shape = (frames_per_file,) + image_size_touple + (1,)\n","    \n","    while count<tam:\n","        \n","        video_name = vid_names[count]\n","        \n","        image_batch = np.zeros(shape=shape, dtype=np.float16)\n","    \n","        image_batch = load_rgb_frames(data_path, video_name)\n","        \n","        shape = (frames_per_file, 14, 14, 512)\n","        transfer_values = np.zeros(shape=shape, dtype=np.float16)\n","        \n","        transfer_values = \\\n","            image_model_transfer.predict(image_batch)\n","         \n","        labels1 = labels[count]\n","        \n","        aux = np.ones([20,2])\n","        \n","        labelss = labels1*aux\n","        \n","        file_path = 'valid/data' + str(count+1) + '.h5'\n","        \n","        with h5py.File(file_path, 'w') as hf:\n","            hf.create_dataset('data', data = transfer_values)\n","            hf.create_dataset('labels', data = labels[count])\n","        \n","        count+=1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T12:42:52.146514Z","iopub.status.busy":"2023-12-10T12:42:52.146231Z","iopub.status.idle":"2023-12-10T12:42:52.160624Z","shell.execute_reply":"2023-12-10T12:42:52.159840Z","shell.execute_reply.started":"2023-12-10T12:42:52.146490Z"},"trusted":true},"outputs":[],"source":["def load_data_test(vid_names, data_path, labels):\n","    \n","    count = 0\n","    \n","    tam = len(vid_names)\n","    \n","    shape = (frames_per_file,) + image_size_touple + (1,)\n","    \n","    while count<tam:\n","        \n","        video_name = vid_names[count]\n","        \n","        image_batch = np.zeros(shape=shape, dtype=np.float16)\n","    \n","        image_batch = load_rgb_frames(data_path, video_name)\n","        \n","        shape = (frames_per_file, 14, 14, 512)\n","        transfer_values = np.zeros(shape=shape, dtype=np.float16)\n","        \n","        transfer_values = \\\n","            image_model_transfer.predict(image_batch)\n","         \n","        labels1 = labels[count]\n","        \n","        aux = np.ones([20,2])\n","        \n","        labelss = labels1*aux\n","        \n","        file_path = 'test/data' + str(count+1) + '.h5'\n","        \n","        with h5py.File(file_path, 'w') as hf:\n","            hf.create_dataset('data', data = transfer_values)\n","            hf.create_dataset('labels', data = labels[count])\n","        \n","        count+=1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T12:42:52.164867Z","iopub.status.busy":"2023-12-10T12:42:52.164606Z","iopub.status.idle":"2023-12-10T12:46:11.532335Z","shell.execute_reply":"2023-12-10T12:46:11.531109Z","shell.execute_reply.started":"2023-12-10T12:42:52.164843Z"},"trusted":true},"outputs":[],"source":["load_data_train(names[0:720], data_path, labels[0:720])\n","load_data_valid(names[720:800], data_path, labels[720:800])\n","load_data_test(names[800:1000], data_path, labels[800:1000])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T12:46:11.534208Z","iopub.status.busy":"2023-12-10T12:46:11.533862Z","iopub.status.idle":"2023-12-10T12:46:11.542295Z","shell.execute_reply":"2023-12-10T12:46:11.541236Z","shell.execute_reply.started":"2023-12-10T12:46:11.534152Z"},"trusted":true},"outputs":[],"source":["os.mkdir('/kaggle/working/train1')\n","os.mkdir('/kaggle/working/valid1')\n","os.mkdir('/kaggle/working/test1')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T12:46:11.544391Z","iopub.status.busy":"2023-12-10T12:46:11.543697Z","iopub.status.idle":"2023-12-10T12:46:11.874405Z","shell.execute_reply":"2023-12-10T12:46:11.873145Z","shell.execute_reply.started":"2023-12-10T12:46:11.544348Z"},"trusted":true},"outputs":[],"source":["def threshold_based_flow_accumulation(current_dir, file_name):\n","    \n","    in_file = os.path.join(current_dir, file_name)\n","    \n","    images = []\n","    \n","    vidcap = cv2.VideoCapture(in_file)\n","    \n","    success,image = vidcap.read()\n","        \n","    count = 0\n","    \n","    flow_result = []\n","    \n","    flow_frame = np.zeros((224, 224))\n","    \n","    mod_frame = np.zeros((224, 224))\n","    \n","    mod_frame.fill(1.25)\n","\n","    while count<21:\n","        \n","        RGB_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","        res = cv2.resize(RGB_img, dsize=(image_size, image_size),\n","                                     interpolation=cv2.INTER_CUBIC)\n","        images.append(res)\n","        \n","        success,image = vidcap.read()\n","        \n","        if(count>0):\n","                \n","            diff_frame = cv2.absdiff(images[count], images[count-1])\n","            res1, threshold_frame1 = cv2.threshold(diff_frame,25,255,cv2.THRESH_BINARY)\n","            flow_frame = flow_frame + threshold_frame1\n","            res2, threshold_frame2 = cv2.threshold(flow_frame, 255, 255, cv2.THRESH_TRUNC)\n","            stacked_img = np.stack((threshold_frame2,)*3, axis=-1)\n","            flow_result.append(stacked_img)\n","            flow_frame = flow_frame/mod_frame\n","        \n","    \n","        count += 1\n","    \n","    answer = np.array(flow_result)\n","    \n","    answer = (answer / 255.).astype(np.float16)\n","    \n","    return answer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T12:46:11.876157Z","iopub.status.busy":"2023-12-10T12:46:11.875855Z","iopub.status.idle":"2023-12-10T12:46:12.936085Z","shell.execute_reply":"2023-12-10T12:46:12.935087Z","shell.execute_reply.started":"2023-12-10T12:46:11.876131Z"},"trusted":true},"outputs":[],"source":["def load_data_train_flow(vid_names, data_path, labels):\n","    \n","    count = 0\n","    \n","    tam = len(vid_names)\n","    \n","    shape = (frames_per_file,) + image_size_touple + (1,)\n","    \n","    while count<tam:\n","        \n","        video_name = vid_names[count]\n","        \n","        image_batch = np.zeros(shape=shape, dtype=np.float16)\n","    \n","        image_batch = threshold_based_flow_accumulation(data_path, video_name)\n","        \n","        shape = (frames_per_file, 14, 14, 512)\n","        transfer_values = np.zeros(shape=shape, dtype=np.float16)\n","        \n","        transfer_values = \\\n","            image_model_transfer.predict(image_batch)\n","         \n","        labels1 = labels[count]\n","        \n","        aux = np.ones([20,2])\n","        \n","        labelss = labels1*aux\n","        \n","        file_path = 'train1/data' + str(count+1) + '.h5'\n","        \n","        with h5py.File(file_path, 'w') as hf:\n","            hf.create_dataset('data', data = transfer_values)\n","            hf.create_dataset('labels', data = labels[count])\n","        \n","        count+=1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T12:46:12.938340Z","iopub.status.busy":"2023-12-10T12:46:12.937572Z","iopub.status.idle":"2023-12-10T12:46:12.966436Z","shell.execute_reply":"2023-12-10T12:46:12.965244Z","shell.execute_reply.started":"2023-12-10T12:46:12.938286Z"},"trusted":true},"outputs":[],"source":["def load_data_valid_flow(vid_names, data_path, labels):\n","    \n","    count = 0\n","    \n","    tam = len(vid_names)\n","    \n","    shape = (frames_per_file,) + image_size_touple + (1,)\n","    \n","    while count<tam:\n","        \n","        video_name = vid_names[count]\n","        \n","        image_batch = np.zeros(shape=shape, dtype=np.float16)\n","    \n","        image_batch = threshold_based_flow_accumulation(data_path, video_name)\n","        \n","        shape = (frames_per_file, 14, 14, 512)\n","        transfer_values = np.zeros(shape=shape, dtype=np.float16)\n","        \n","        transfer_values = \\\n","            image_model_transfer.predict(image_batch)\n","         \n","        labels1 = labels[count]\n","        \n","        aux = np.ones([20,2])\n","        \n","        labelss = labels1*aux\n","        \n","        file_path = 'valid1/data' + str(count+1) + '.h5'\n","        \n","        with h5py.File(file_path, 'w') as hf:\n","            hf.create_dataset('data', data = transfer_values)\n","            hf.create_dataset('labels', data = labels[count])\n","        \n","        count+=1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T12:46:12.968459Z","iopub.status.busy":"2023-12-10T12:46:12.968090Z","iopub.status.idle":"2023-12-10T12:46:12.987044Z","shell.execute_reply":"2023-12-10T12:46:12.985951Z","shell.execute_reply.started":"2023-12-10T12:46:12.968432Z"},"trusted":true},"outputs":[],"source":["def load_data_test_flow(vid_names, data_path, labels):\n","    \n","    count = 0\n","    \n","    tam = len(vid_names)\n","\n","    shape = (frames_per_file,) + image_size_touple + (1,)\n","    \n","    while count<tam:\n","        \n","        video_name = vid_names[count]\n","        \n","        image_batch = np.zeros(shape=shape, dtype=np.float16)\n","    \n","        image_batch = threshold_based_flow_accumulation(data_path, video_name)\n","        \n","        shape = (frames_per_file, 14, 14, 512)\n","        transfer_values = np.zeros(shape=shape, dtype=np.float16)\n","        \n","        transfer_values = \\\n","            image_model_transfer.predict(image_batch)\n","         \n","        labels1 = labels[count]\n","        \n","        aux = np.ones([20,2])\n","        \n","        labelss = labels1*aux\n","        \n","        file_path = 'test1/data' + str(count+1) + '.h5'\n","        \n","        with h5py.File(file_path, 'w') as hf:\n","            hf.create_dataset('data', data = transfer_values)\n","            hf.create_dataset('labels', data = labels[count])\n","        \n","        count+=1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T12:46:12.989053Z","iopub.status.busy":"2023-12-10T12:46:12.988595Z","iopub.status.idle":"2023-12-10T12:49:45.251383Z","shell.execute_reply":"2023-12-10T12:49:45.250148Z","shell.execute_reply.started":"2023-12-10T12:46:12.989011Z"},"trusted":true},"outputs":[],"source":["load_data_train_flow(names[0:720], data_path, labels[0:720])\n","load_data_valid_flow(names[720:800], data_path, labels[720:800])\n","load_data_test_flow(names[800:1000], data_path, labels[800:1000])"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":1132746,"sourceId":1900619,"sourceType":"datasetVersion"}],"dockerImageVersionId":30615,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
